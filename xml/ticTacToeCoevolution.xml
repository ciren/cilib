<?xml version="1.0"?>

<!DOCTYPE simulator [
<!ATTLIST algorithm id ID #IMPLIED>
<!ATTLIST problem id ID #IMPLIED>
<!ATTLIST measurements id ID #IMPLIED>
]>

<simulator>
    <problem id="ttt" class="problem.coevolution.CompetitiveCoevolutionGameLearningOptimizationProblem" numberOfEvaluations="1">
        <game class="games.game.tictactoe.TicTacToe">
            <agent class="games.agent.state.StateEvaluationAgent">
                <traversalStrategy class="games.agent.state.traversal.MinMaxAlphaBetaTraversalStrategy" MaxDepth="1">
                    <evaluator class="games.agent.state.evaluation.NeuralStateEvaluator">
                        <neuralNetwork class="nn.NeuralNetwork">
                            <architecture class="nn.architecture.Architecture">
                                <architectureBuilder class="nn.architecture.builder.FeedForwardArchitectureBuilder">
                                    <addLayer class="nn.architecture.builder.LayerConfiguration"/> <!-- size is specified by neural input strategy-->
                                    <addLayer class="nn.architecture.builder.LayerConfiguration" size="2"/>
                                    <addLayer class="nn.architecture.builder.LayerConfiguration"/> <!-- size is specified by output interpretation strategy-->
                                    <layerBuilder class="nn.architecture.builder.PrototypeFullyConnectedLayerBuilder" domain="R(-1,1)" />
                                </architectureBuilder>
                            </architecture>
                        </neuralNetwork>
                        <stateInputStrategy class="games.game.tictactoe.TTTStateInputStrategy"/>
                    </evaluator>
                </traversalStrategy>
            </agent>
            <agent class="games.agent.state.StateEvaluationAgent">
                <traversalStrategy class="games.agent.state.traversal.MinMaxAlphaBetaTraversalStrategy" MaxDepth="1">
                    <evaluator class="games.agent.state.evaluation.NeuralStateEvaluator">
                        <neuralNetwork class="nn.NeuralNetwork">
                            <architecture class="nn.architecture.Architecture">
                                <architectureBuilder class="nn.architecture.builder.FeedForwardArchitectureBuilder">
                                    <addLayer class="nn.architecture.builder.LayerConfiguration"/> <!-- size is specified by neural input strategy-->
                                    <addLayer class="nn.architecture.builder.LayerConfiguration" size="2"/>
                                    <addLayer class="nn.architecture.builder.LayerConfiguration"/> <!-- size is specified by output interpretation strategy-->
                                    <layerBuilder class="nn.architecture.builder.PrototypeFullyConnectedLayerBuilder" domain="R(-1,1)" />
                                </architectureBuilder>
                            </architecture>
                        </neuralNetwork>
                        <stateInputStrategy class="games.game.tictactoe.TTTStateInputStrategy"/>
                    </evaluator>
                </traversalStrategy>
            </agent>
            <scoringStrategy class="games.game.scoring.WinLoseDrawValueScoringStrategy"/>
        </game>
    </problem>

    <algorithms>
        <algorithm id="lbest" class="pso.PSO">
            <iterationStrategy class = "pso.dynamic.DynamicIterationStrategy">
            <IterationStrategy class = "pso.iterationstrategies.ASynchronousIterationStrategy"/>
                <DetectionStrategy class = "pso.dynamic.detectionstrategies.PeriodicDetectionStrategy" IterationsModulus="50"/>
                <ResponseStrategy class = "pso.dynamic.responsestrategies.CompetitiveCoevolutionParticleReevaluationResponseStrategy"/>
            </iterationStrategy>
            <initialisationStrategy class="algorithm.initialisation.ChargedPopulationInitialisationStrategy" entityNumber="30">
                <entityType class="pso.dynamic.ChargedParticle">
                    <neighbourhoodBestUpdateStrategy class = "pso.positionprovider.IterationNeighbourhoodBestUpdateStrategy"/>
                </entityType>
            </initialisationStrategy>
            <topology class="entity.topologies.LBestTopology">
                <neighbourhoodSize class = "controlparameter.ConstantControlParameter" parameter = "3"/>
            </topology>
        </algorithm>

        <algorithm id="compcoevol" class="coevolution.CoevolutionAlgorithm">
            <addStoppingCondition class="stoppingcondition.MaximumIterations" maximumIterations="1000"/>
            <coevolutionIterationStrategy class="coevolution.CompetitiveCoevolutionIterationStrategy">
                <opponentSelectionStrategy class="coevolution.selection.SelectNOpponentSelectionStrategy" numberOfOpponents="20">
                    <addPoolSelectionStrategy class = "coevolution.selection.SelectpBestSolutionsPoolSelectionStrategy"/>
                    <addPoolSelectionStrategy class = "coevolution.selection.SelectHOFPoolSelectionStrategy" HOFSize = "20" AddToHOFEpoch="20"/>
                </opponentSelectionStrategy>
            </coevolutionIterationStrategy>
        </algorithm>
    </algorithms>

    <measurements id="fitness" class="simulator.MeasurementSuite" resolution="10">
        <addMeasurement class="measurement.multiple.MultiPopulationFitness"/>
    </measurements>

    <simulations>
        <simulation samples="1">
            <algorithm idref="compcoevol">
            <algorithm idref="lbest"/>
            <algorithm idref="lbest"/>
            </algorithm>
            <problem idref="ttt"/>
            <measurements idref="fitness" />
            <output format="TXT" file="data/TTTCoEvolution.txt"/>
        </simulation>
    </simulations>
</simulator>
